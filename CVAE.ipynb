{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CVAE.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPgYZgRqGyKRP9ATtbBjMRQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarkAvilin1/DS-and-ML/blob/main/CVAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULHsebxJMSqQ"
      },
      "source": [
        "#**Задание Ultra Pro**\n",
        "Модель генерации с помощью Conditional Variational AutoEncoder (CVAE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqO9lcd7MR1T"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Dense, Input, Lambda, Flatten, Reshape \n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from IPython.display import clear_output, Image\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow.keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOb6dj-Doief"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data() \n",
        "\n",
        "x_train = x_train/255 \n",
        "x_test  = x_test/255 \n",
        "\n",
        "\n",
        "x_train = np.expand_dims(x_train, axis=-1) \n",
        "x_test = np.expand_dims(x_test, axis=-1) \n",
        "\n",
        "y_test_int, y_train_int = y_test.copy(), y_train.copy()\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6DBl0j5oFZG"
      },
      "source": [
        "batch_size = 100 \n",
        "latent_dim = 20 \n",
        "dropout_rate = 0.3 \n",
        "start_lr = 0.0001 \n",
        "img_height = x_train.shape[1]\n",
        "img_width = x_train.shape[2] \n",
        "img_chanels = x_train.shape[3] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG5PmFfM3jTN"
      },
      "source": [
        "def apply_bn_and_dropout(x):\n",
        "  x = Dropout(dropout_rate) (x) \n",
        "  x = BatchNormalization() (x) \n",
        "  return x\n",
        "\n",
        "\n",
        "def sampling(args): \n",
        "  z_mean, z_log_var = args \n",
        "  epsilon = K.random_normal(shape=(latent_dim,), mean=0., stddev=1.0)\n",
        "  sampling_layer = z_mean + K.exp(z_log_var / 2) * epsilon \n",
        "  return sampling_layer\n",
        "\n",
        "\n",
        "\n",
        "def vae_loss(x, decoded):  \n",
        "  kl_loss = -0.5 * K.sum(1.0 + z_log_var_model([x,num_elements]) - K.square(z_mean_model([x,num_elements])) - K.exp(z_log_var_model([x,num_elements])), axis=-1) # по формуле кульбака-лейблера устанавливаем ошибку\n",
        "\n",
        "  x = K.reshape(x, (-1, img_height*img_width)) \n",
        "  decoded = K.reshape(decoded, (-1, img_height*img_width)) \n",
        "  xent_loss = img_height*img_width*binary_crossentropy(x, decoded) \n",
        "\n",
        "  res = (xent_loss + kl_loss)/2.0/img_height/img_width \n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6_62_4pXCAE"
      },
      "source": [
        "en_in = Input((img_height, img_width, img_chanels)) \n",
        "en = Flatten() (en_in) \n",
        "class_1 = Input(shape=(10))  \n",
        "en = concatenate([en, class_1])\n",
        "en = Dense(256, activation='relu') (en) \n",
        "en = Dense(128, activation='relu') (en) \n",
        "en = apply_bn_and_dropout(en) \n",
        "\n",
        "z_mean = Dense(latent_dim) (en) \n",
        "z_log_var = Dense(latent_dim) (en) \n",
        "\n",
        "l = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])  \n",
        "\n",
        "\n",
        "dec_in = Input(shape =(latent_dim,)) \n",
        "class_2 = Input(shape=(10,))\n",
        "dec = concatenate([dec_in, class_2])\n",
        "dec = Dense(128) (dec) \n",
        "dec = LeakyReLU()(dec) \n",
        "dec = apply_bn_and_dropout(dec) \n",
        "dec = Dense(256) (dec)\n",
        "dec = LeakyReLU()(dec) \n",
        "dec = apply_bn_and_dropout(dec) \n",
        "dec = Dense(img_height*img_width, activation='sigmoid') (dec) \n",
        "dec = Reshape((img_height, img_width, img_chanels)) (dec) \n",
        "\n",
        "encoder = Model([en_in, class_1], l)\n",
        "\n",
        "decoder = Model([dec_in, class_2], dec) \n",
        "\n",
        "z_mean_model = Model([en_in, class_1], z_mean)  \n",
        "\n",
        "z_log_var_model = Model([en_in, class_1], z_log_var)\n",
        "\n",
        "CVAE = Model([en_in, class_1, class_2], decoder([encoder([en_in, class_1]), class_2])) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOFOYdRVXELO"
      },
      "source": [
        "CVAE.compile(loss=vae_loss, optimizer=Adam(start_lr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4n06L98XHGW",
        "outputId": "692121bb-1a63-4adc-9b6a-09c70df9e04c"
      },
      "source": [
        "CVAE.fit([x_train, y_train, y_train], x_train, batch_size=batch_size, epochs=50, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "600/600 [==============================] - 6s 8ms/step - loss: 0.3059\n",
            "Epoch 2/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.1532\n",
            "Epoch 3/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.1127\n",
            "Epoch 4/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.1035\n",
            "Epoch 5/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0991\n",
            "Epoch 6/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0963\n",
            "Epoch 7/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0943\n",
            "Epoch 8/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0925\n",
            "Epoch 9/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0910\n",
            "Epoch 10/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0896\n",
            "Epoch 11/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0885\n",
            "Epoch 12/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0874\n",
            "Epoch 13/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0864\n",
            "Epoch 14/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0856\n",
            "Epoch 15/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0847\n",
            "Epoch 16/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0840\n",
            "Epoch 17/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0834\n",
            "Epoch 18/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0827\n",
            "Epoch 19/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0821\n",
            "Epoch 20/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0816\n",
            "Epoch 21/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0810\n",
            "Epoch 22/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0804\n",
            "Epoch 23/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0799\n",
            "Epoch 24/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0796\n",
            "Epoch 25/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0792\n",
            "Epoch 26/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0788\n",
            "Epoch 27/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0785\n",
            "Epoch 28/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0781\n",
            "Epoch 29/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0778\n",
            "Epoch 30/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0775\n",
            "Epoch 31/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0773\n",
            "Epoch 32/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0770\n",
            "Epoch 33/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0767\n",
            "Epoch 34/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0765\n",
            "Epoch 35/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0763\n",
            "Epoch 36/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0761\n",
            "Epoch 37/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0759\n",
            "Epoch 38/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0758\n",
            "Epoch 39/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0755\n",
            "Epoch 40/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0754\n",
            "Epoch 41/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0753\n",
            "Epoch 42/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0751\n",
            "Epoch 43/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0750\n",
            "Epoch 44/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0748\n",
            "Epoch 45/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0748\n",
            "Epoch 46/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0746\n",
            "Epoch 47/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0746\n",
            "Epoch 48/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0745\n",
            "Epoch 49/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0743\n",
            "Epoch 50/50\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0742\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa2601f2e90>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvJOzl3zsCuI",
        "outputId": "98b6abd5-729a-45b9-f94a-dd056d07eacc"
      },
      "source": [
        "CVAE.fit([x_train, y_train, y_train], x_train, batch_size=batch_size, epochs=20, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0742\n",
            "Epoch 2/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0740\n",
            "Epoch 3/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0739\n",
            "Epoch 4/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0738\n",
            "Epoch 5/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0737\n",
            "Epoch 6/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0736\n",
            "Epoch 7/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0736\n",
            "Epoch 8/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0735\n",
            "Epoch 9/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0735\n",
            "Epoch 10/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0734\n",
            "Epoch 11/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0732\n",
            "Epoch 12/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0732\n",
            "Epoch 13/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0732\n",
            "Epoch 14/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0729\n",
            "Epoch 15/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0729\n",
            "Epoch 16/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0728\n",
            "Epoch 17/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0728\n",
            "Epoch 18/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0728\n",
            "Epoch 19/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0727\n",
            "Epoch 20/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0727\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa25995ab50>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTG0xb6Ks2yr",
        "outputId": "7f3eba9a-9d82-465c-e6de-dababa98d73a"
      },
      "source": [
        "CVAE.fit([x_train, y_train, y_train], x_train, batch_size=batch_size, epochs=20, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0720\n",
            "Epoch 2/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0720\n",
            "Epoch 3/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0719\n",
            "Epoch 4/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0719\n",
            "Epoch 5/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0718\n",
            "Epoch 6/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0717\n",
            "Epoch 7/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0718\n",
            "Epoch 8/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0717\n",
            "Epoch 9/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0716\n",
            "Epoch 10/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0716\n",
            "Epoch 11/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0715\n",
            "Epoch 12/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0716\n",
            "Epoch 13/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0716\n",
            "Epoch 14/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0715\n",
            "Epoch 15/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0715\n",
            "Epoch 16/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0714\n",
            "Epoch 17/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0715\n",
            "Epoch 18/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0714\n",
            "Epoch 19/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0714\n",
            "Epoch 20/20\n",
            "600/600 [==============================] - 5s 8ms/step - loss: 0.0713\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa259956510>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    }
  ]
}